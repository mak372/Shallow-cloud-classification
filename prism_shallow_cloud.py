# -*- coding: utf-8 -*-
"""Prism- Shallow cloud.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qSrhzqypGlLm7Bx1u5c7u-648Ygb_RjI
"""

!nvidia-smi

from google.colab import drive
drive.mount('/content/drive')

path= "/content/drive/My Drive/understanding_cloud_organization/"

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x

import tensorflow as tf

print(tf. __version__)

import matplotlib.image as mpimg                      
from skimage.measure import label, regionprops
import os, random, cv2, gc, math, matplotlib
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

train_df        = pd.read_csv(path + 'train.csv')

#Splitting image_Label into image file name and images category 
train_df['ImageId'] = train_df['Image_Label'].apply(lambda x: x.split('_')[0])
train_df['ClassId'] = train_df['Image_Label'].apply(lambda x: x.split('_')[1])

#checking whether images have masks or not
train_df['hasMask'] = ~ train_df['EncodedPixels'].isna()

#replacing EncodedPixels NaN value by '00 00'
train_df['EncodedPixels'] = train_df['EncodedPixels'].apply(lambda x: '00 00' if type(x)==float else x)

conditions = [ ( train_df['ClassId'].str.contains('Fish') & train_df['hasMask']== True), 
              ( train_df['ClassId'].str.contains('Flower') & train_df['hasMask']== True), 
              ( train_df['ClassId'].str.contains('Gravel') & train_df['hasMask']== True), 
              ( train_df['ClassId'].str.contains('Sugar') & train_df['hasMask']== True),
              ( train_df['hasMask']== False)
            ]

# images with NaN encodedPixels values will be labeled false
# images with numeric encodedPixels values will have the labels with their corresponding category
train_df['check'] = np.select(conditions, ['True_Fish', 'True_Flower','True_Gravel', 'True_Sugar', 'False' ])

train_df.head(5)

y = train_df.check.value_counts()
mylabels = ['NULL', 'Sugar', 'Gravel', 'Fish', 'Flower']
colors = ['c', 'g', 'y', '#B14CE8','#3070CD']
plt.pie(y, labels = mylabels, 
        autopct='%1.1f%%', 
        colors = colors,
        explode = (0.09, 0.1, 0.1, 0.1, 0.1),
        shadow=True, 
        startangle=90)
plt.axis('equal')
plt.show()

# counting maximum number of masks in each image
mask_count_df = train_df.groupby('ImageId').agg(np.sum).reset_index()
print(mask_count_df.shape)
print(mask_count_df.head(100))

plt.figure(figsize=(9, 6))
mask_count_df.hasMask.value_counts(dropna= False).plot(kind = 'bar', color='#944dff')
plt.ylabel('Numbers of Images', fontsize=14)
plt.xlabel('Numbers of Masks', fontsize=14)
plt.title('Masks in Dataset', fontsize=16)
plt.xticks(rotation=0)

#bargraph for number of images  each category
plt.figure(figsize=(9, 6))
categories = ['Sugar','Flower','gravel', 'Fish']
counts = train_df.check.value_counts()[1:]
plt.bar(categories, counts, color = '#355EDF')
plt.title('Category wise Distribution ', fontsize=16)
plt.show()

def rle_to_mask(rleString,height= 1400,width= 2100):
  rows,cols = height,width
  rleNumbers = [int(numstring) for numstring in rleString.split(' ')]
  rlePairs = np.array(rleNumbers).reshape(-1,2)
  img = np.zeros(rows*cols,dtype=np.uint8)
  for index,length in rlePairs:
    index -= 1
    img[index:index+length] = 255
  img = img.reshape(cols,rows)
  img = img.T
  return img



# converting rgb to grayscale image
def rgb_to_gray(img):
        grayImage = np.zeros(img.shape)
        R = np.array(img[:, :, 0])
        G = np.array(img[:, :, 1])
        B = np.array(img[:, :, 2])

        R = (R *.299)
        G = (G *.587)
        B = (B *.114)

        Avg = (R+G+B)
        grayImage = img.copy()

        for i in range(3):
           grayImage[:,:,i] = Avg
           
        return grayImage

train_images = '/content/drive/MyDrive/understanding_cloud_organization/train_images'

#creating rles
colors = [(0,0,255), (255,0,0), (0,255,0), (255,255,0)]
image_name = '0ff2c12.jpg'

rles = train_df[train_df['ImageId']==image_name]['EncodedPixels'].reset_index(drop=True)
image_start = plt.imread(os.path.join(train_images, image_name))
rles.head()

def trace_boundingBox(image : np.ndarray,
                      mask : np.ndarray,
                      color : tuple = (0,0,255),
                      width : int = 27):
    """
    Draw a bounding box on image

     Parameter
     ----------
     image : image on which we want to draw the box 
     mask  : mask to process
     color : color we want to use to draw the box edges
     width : box edges's width

    """
    
    lbl = label(mask)
    props = regionprops(lbl)
    for prop in props:
        coin1 = (prop.bbox[3], prop.bbox[2])
        coin2 = (prop.bbox[1], prop.bbox[0])
        cv2.rectangle(image, coin2, coin1, color, width)
        # cv2.putText(image,'text', (prop.bbox[3], prop.bbox[2]+30), cv2.FONT_HERSHEY_SIMPLEX, 10, (0,255,0), 2)

labels = ['NULL', 'Sugar', 'Gravel', 'Fish', 'Flower']

import warnings
from tqdm import tqdm_notebook
import tensorflow as tf
try:
    from tensorflow.contrib import keras as keras
    print ('load keras from tensorflow package')
except:
    print ('update your tensorflow')
from tensorflow.contrib.keras import models
from tensorflow.contrib.keras import layers

from keras import backend as K
from keras.optimizers import Adam, SGD
from keras.models import Model
from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose
warnings.filterwarnings("ignore")

img_width   = 128 
img_height  = 128
num_classes = 4
tr          = pd.read_csv(path + 'train.csv')
print(len(tr))
tr.head()

def rle2mask(rle, imgshape):
    width = imgshape[0]
    height= imgshape[1]
    
    mask= np.zeros( width*height ).astype(np.uint8)
    
    array = np.asarray([int(x) for x in rle.split()])
    starts = array[0::2]
    lengths = array[1::2]

    current_position = 0
    for index, start in enumerate(starts):
        mask[int(start):int(start+lengths[index])] = 1
        current_position += lengths[index]
        
    return np.flipud( np.rot90( mask.reshape(height, width), k=1 ) )

def mask2rle(img):
    pixels= img.T.flatten()
    pixels = np.concatenate([[0], pixels, [0]])
    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1
    runs[1::2] -= runs[::2]
    return ' '.join(str(x) for x in runs)

img_names_all = tr['Image_Label'].apply(lambda x: x.split('_')[0]).unique()
len(img_names_all)

new_ep = True
def keras_generator(batch_size):  
    global new_ep
    while True:   
        
        x_batch = []
        y_batch = []        
        for _ in range(batch_size):                         
            if new_ep == True:
                img_names =  img_names_all
                new_ep = False
            
            fn = img_names[random.randrange(0, len(img_names))]                                   

            img = cv2.imread(path + 'train_images/'+ fn)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)                       
            masks = []
            for rle in tr[tr['Image_Label'].apply(lambda x: x.split('_')[0]) == fn]['EncodedPixels']:                
                if pd.isnull(rle):
                    mask = np.zeros((img_width, img_height))
                else:
                    mask = rle2mask(rle, img.shape)
                    mask = cv2.resize(mask, (img_width, img_height))
                masks.append(mask)                                        
            img = cv2.resize(img, (img_width, img_height))            
            x_batch += [img]
            y_batch += [masks] 

            img_names = img_names[img_names != fn]   
 
        x_batch = np.array(x_batch)
        y_batch = np.transpose(np.array(y_batch), (0, 2, 3, 1))        

        yield x_batch, y_batch

def get_model():
    inputs = Input((img_width,img_height, 3))
    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)
    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)
    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)
    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)

    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)
    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)

    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)
    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)

    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)
    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)
    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)

    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)
    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)
    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)

    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)
    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)
    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)

    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)
    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)
    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)

    conv10 = Conv2D(num_classes, (1, 1), activation='sigmoid')(conv9)

    model = Model(inputs=[inputs], outputs=[conv10])

    model.compile(optimizer='sgd', loss='binary_crossentropy',metrics=['accuracy'])

    return model

model = get_model()
model.summary()

class EpochBegin(keras.callbacks.Callback):
    def on_epoch_begin (self, epoch, logs={}):
        global new_ep
        new_ep = True
Epoch_Begin_Clb = EpochBegin()

reduce_learning_rate = tf.keras.callbacks.ReduceLROnPlateau(
                              monitor='loss',
                              mode='auto',
                              factor=0.666,
                              patience=1,
                              min_lr=0,
                              cooldown=0,
                              verbose=1)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# batch_size=16
# history = model.fit_generator(keras_generator(batch_size),
#               steps_per_epoch=200,                    
#               epochs=3,
#               callbacks=[Epoch_Begin_Clb])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# test_img = []
# testfiles=os.listdir(path + 'test_images/')
# for fn in tqdm_notebook(testfiles):     
#         img = cv2.imread( path + 'test_images/'+fn )
#         img = cv2.resize(img,(img_width, img_height))       
#         test_img.append(img)
# len(test_img)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# predict = model.predict(np.asarray(test_img))

predict.shape

pred_rle[0]

colors = [(0,0,255), (255,0,0), (0,255,0), (255,255,0)]  # B, R ,G, Y colors

#subplots
for i in range(0, 13, 4):
  plt.figure(figsize=(20, 10))                                  
      
  image_name = train_df.loc[train_df.index[i]]['ImageId']       # fetching image name
  image = mpimg.imread(os.path.join(train_images, image_name))  # storing image in the form of np.array

  # ploting original image
  plt.subplot(2, 5, 1)                                           # 1st picture of 1st row
  plt.title('Original image')
  plt.imshow(image)
  plt.ylabel(train_df.loc[train_df.index[i]]['ImageId'])         # name of first image

  # Detecting fish pattern in image
  plt.subplot(2, 5, 2)                                           # 2nd picture of 1st row
  rle = df.loc[df.index[i]]['EncodedPixels']         # initialize the current RLE code
  if not isinstance(rle, float):                                 # it's not a 'NaN' RLE
      mask = rle_to_mask(rle)                                    
      trace_boundingBox(image, mask, color=colors[0])            # draw boundingBox on original image with blue color
  plt.title(df.loc[df.index[i]]['ClassId'])
  plt.imshow(image)
  plt.axis(False)                                              


  # Detecting flower pattern in image
  image = mpimg.imread(os.path.join(images, image_name))    
  plt.subplot(2, 5, 3)
  rle = df.loc[df.index[i+1]]['EncodedPixels']                    
  if not isinstance(rle, float):                                             
      mask = rle_to_mask(rle)
      trace_boundingBox(image, mask, color=colors[1])
  plt.title(df.loc[df.index[i+1]]['ClassId'])
  plt.imshow(image)
  plt.axis(False)

  # Detecting gravel pattern in image
  image = mpimg.imread(os.path.join(images, image_name))
  plt.subplot(2, 5, 4)
  rle = df.loc[df.index[i+2]]['EncodedPixels']                   
  if not isinstance(rle, float):
      mask = rle_to_mask(rle)
      trace_boundingBox(image, mask, color=colors[2])
  plt.title(df.loc[df.index[i+2]]['ClassId'])
  plt.imshow(image)
  plt.axis(False)

  # Detecting sugar pattern in image
  image = mpimg.imread(os.path.join(images, image_name))
  plt.subplot(2, 5, 5)
  rle = df.loc[df.index[i+3]]['EncodedPixels']                   
  if not isinstance(rle, float): 
      mask = rle_to_mask(rle)
      trace_boundingBox(image, mask, color=colors[3])
  plt.title(df.loc[df.index[i+3]]['ClassId'])

  plt.imshow(image)
  plt.axis(False)



plot_model(
    model,
    to_file="model layers.png",
    show_shapes=False,
    show_layer_names=True,
    rankdir="TB"
)



# plot model architecture
from tensorflow.keras.utils import plot_model
plot_model(model, to_file='model architecture.png',show_shapes=True)

smooth = 1.
def dice_coef(y_true, y_pred):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)


def dice_coef_loss(y_true, y_pred):
    return -dice_coef(y_true, y_pred)

#     sgd = SGD(lr=0.01, decay=1e-6, momentum=0.3, nesterov=False)
#     model.compile(optimizer=Adam(lr=0.001), loss=dice_coef_loss, metrics=[dice_coef])



# # save model
# from keras.models import model_from_json
# # serialize model to JSON
# model_json = model.to_json()
# with open("model.json", "w") as json_file:
#     json_file.write(model_json)



# #load json and create model
# from keras.models import model_from_json
# json_file = open('model_3_epochs.json', 'r')
# loaded_model_json = json_file.read()
# json_file.close()
# model = model_from_json(loaded_model_json)
# model.summary()



fig, axs = plt.subplots(5, figsize=(20, 20))
axs[0].imshow(cv2.resize(plt.imread(path + 'test_images/' + testfiles[0]),(525, 350)))
for i in range(4):
    axs[i+1].imshow(rle2mask(pred_rle[i], img.shape), cmap = "Greys")



fig, axs = plt.subplots(5, figsize=(20, 20))
axs[0].imshow(cv2.resize(plt.imread(path + 'test_images/' + testfiles[1]),(525, 350)))
k=4
for i in range(4):
    axs[i+1].imshow(rle2mask(pred_rle[k], img.shape), cmap = "Greys")
    k= k+1



plt.figure(figsize=(18, 10))
    
plt.subplot(2, 5, 1) 
img = cv2.resize(plt.imread(path + 'test_images/' + testfiles[0]),(525, 350))
plt.imshow(img)


# fish
plt.subplot(2, 5, 2)  
mask = rle2mask(pred_rle[0], img.shape)
img = cv2.resize(plt.imread(path + 'test_images/' + testfiles[0]),(525, 350))
trace_boundingBox(img, mask, color=colors[0])
plt.title("Fish")
plt.imshow(img)

# flower
plt.subplot(2, 5, 3)  
mask = rle2mask(pred_rle[1], img.shape)
img = cv2.resize(plt.imread(path + 'test_images/' + testfiles[0]),(525, 350))
trace_boundingBox(img, mask, color=colors[1])
plt.title("flower")
plt.imshow(img)

#gravel
plt.subplot(2, 5, 4)  
mask = rle2mask(pred_rle[2], img.shape)
img = cv2.resize(plt.imread(path + 'test_images/' + testfiles[0]),(525, 350))
trace_boundingBox(img, mask, color=colors[2])
plt.title("gravel")
plt.imshow(img)

#sugar
plt.subplot(2, 5, 5)  
mask = rle2mask(pred_rle[3], img.shape)
img = cv2.resize(plt.imread(path + 'test_images/' + testfiles[1]),(525, 350))
trace_boundingBox(img, mask, color=colors[3])
plt.title("Sugar")
plt.imshow(img)



plt.plot(history.history['accuracy'])
plt.plot(history.history['loss'])
plt.title('model performance')
plt.xlabel('epoch')
plt.legend(['accuracy', 'loss'], loc='right')
plt.savefig('model performance.png')



print(history.history.keys())



plt.plot(history.history['accuracy'])
plt.title('Model Accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.savefig('accuracy curve.png')

plt.plot(history.history['loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.savefig('loss curve.png')

gc.collect()



sub = pd.read_csv( path + 'sample_submission.csv', converters={'EncodedPixels': lambda e: ' '} )
sub['EncodedPixels'] = pred_rle
sub.head()

sub.to_csv('submission.csv', index=False)

fig, axs = plt.subplots(5, figsize=(20, 20))
axs[0].imshow(cv2.resize(plt.imread(path + 'test_images/' + testfiles[0]),(525, 350)))
for i in range(4):
    axs[i+1].imshow(rle2mask(pred_rle[i], img.shape),cmap ='gray')

# Commented out IPython magic to ensure Python compatibility.
# %%time
# pred_rle = []
# for img in predict:   
#     img = cv2.resize(img, (525, 350))
#     tmp = np.copy(img)
#     tmp[tmp<np.mean(img)] = 0
#     tmp[tmp>0] = 1
#     for i in range(tmp.shape[-1]):
#         pred_rle.append(mask2rle(tmp[:,:,i]))
# len(pred_rle)



import matplotlib.image as mpimg 
colors = [(0,0,255), (255,0,0), (0,255,0), (255,255,0)]  # B, R ,G, Y colors
for i in range(0, 13, 4):
    plt.figure(figsize=(18, 10))
    
    plt.subplot(2, 5, 1) 
    img = cv2.resize(plt.imread(path + 'test_images/' + testfiles[i]),(525, 350))
    plt.imshow(img)


    # fish
    plt.subplot(2, 5, 2)  
    mask = rle2mask(pred_rle[0+i], img.shape)
    img = cv2.resize(plt.imread(path + 'test_images/' + testfiles[i]),(525, 350))
    trace_boundingBox(img, mask, color=colors[0])
    plt.title("Fish")
    plt.imshow(img)

    # flower
    plt.subplot(2, 5, 3)  
    mask = rle2mask(pred_rle[i+1], img.shape)
    img = cv2.resize(plt.imread(path + 'test_images/' + testfiles[i]),(525, 350))
    trace_boundingBox(img, mask, color=colors[1])
    plt.title("flower")
    plt.imshow(img)

    #gravel
    plt.subplot(2, 5, 4)  
    mask = rle2mask(pred_rle[2+i], img.shape)
    img = cv2.resize(plt.imread(path + 'test_images/' + testfiles[i]),(525, 350))
    trace_boundingBox(img, mask, color=colors[2])
    plt.title("gravel")
    plt.imshow(img)

    #sugar
    plt.subplot(2, 5, 5)  
    mask = rle2mask(pred_rle[i+3], img.shape)
    img = cv2.resize(plt.imread(path + 'test_images/' + testfiles[i]),(525, 350))
    trace_boundingBox(img, mask, color=colors[3])
    plt.title("Sugar")
    plt.imshow(img)



from skimage.measure import label, regionprops
def trace_boundingBox(image : np.ndarray,
                      mask : np.ndarray,
                      color : tuple = (0,0,255),
                      width : int = 27):
    """
    Draw a bounding box on image

     Parameter
     ----------
     image : image on which we want to draw the box 
     mask  : mask to process
     color : color we want to use to draw the box edges
     width : box edges's width

    """
    
    lbl = label(mask)
    props = regionprops(lbl)
    for prop in props:
        coin1 = (prop.bbox[3], prop.bbox[2])
        coin2 = (prop.bbox[1], prop.bbox[0])
        cv2.rectangle(image, coin2, coin1, color, width)